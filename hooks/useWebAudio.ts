'use client';

import { useState, useRef, useCallback, useEffect } from 'react';
import { getSharedAudioContext, resumeAudioContext } from '@/utils/sharedAudioContext';

// AudioUrls íƒ€ì… ì •ì˜
export interface AudioUrls {
  intro: string;
  chorus: string;
  outro: string;
}

// í›… ì˜µì…˜ íƒ€ì…
export interface UseWebAudioOptions {
  chorusRepeat?: number; // chorus ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 4, Singleì€ 1)
}

// í›… ë°˜í™˜ íƒ€ì…
export interface UseWebAudioReturn {
  isLoading: boolean;
  isReady: boolean;
  isPlaying: boolean;
  currentTime: number;
  duration: number;
  volume: number;
  loadAudio: (urls: AudioUrls) => Promise<void>;
  play: () => Promise<void>;
  pause: () => void;
  seek: (time: number) => void;
  stop: () => void;
  setVolume: (value: number) => void;
}

/**
 * Web Audio API ê¸°ë°˜ ì˜¤ë””ì˜¤ ì¬ìƒ í›…
 * intro + chorusÃ—N + outroë¥¼ í•˜ë‚˜ì˜ ì—°ì† ë²„í¼ë¡œ í•©ì„±í•˜ì—¬ ì¬ìƒ
 *
 * @param options.chorusRepeat - chorus ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸ê°’: 4 for Feed, 1 for Single)
 */
export function useWebAudio(options: UseWebAudioOptions = {}): UseWebAudioReturn {
  const { chorusRepeat = 4 } = options;
  // ìƒíƒœ
  const [isLoading, setIsLoading] = useState(false);
  const [isReady, setIsReady] = useState(false);
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [volume, setVolumeState] = useState(1); // 0~1 ë²”ìœ„

  // refs
  const audioContextRef = useRef<AudioContext | null>(null);
  const combinedBufferRef = useRef<AudioBuffer | null>(null);
  const sourceNodeRef = useRef<AudioBufferSourceNode | null>(null);
  const gainNodeRef = useRef<GainNode | null>(null); // ë³¼ë¥¨ ì¡°ì ˆìš©
  const startTimeRef = useRef<number>(0); // AudioContext.currentTime at play start
  const pauseOffsetRef = useRef<number>(0); // ì¼ì‹œì •ì§€ ì‹œ ìœ„ì¹˜
  const animationFrameRef = useRef<number | null>(null);
  const isPlayingRef = useRef(false); // isPlayingì˜ ref ë²„ì „ (ì½œë°±ì—ì„œ ì‚¬ìš©)
  const durationRef = useRef(0); // durationì˜ ref ë²„ì „

  // isPlaying ìƒíƒœì™€ ref ë™ê¸°í™”
  useEffect(() => {
    isPlayingRef.current = isPlaying;
  }, [isPlaying]);

  // duration ìƒíƒœì™€ ref ë™ê¸°í™”
  useEffect(() => {
    durationRef.current = duration;
  }, [duration]);

  /**
   * ê³µìœ  AudioContext íšë“ (ì‹±ê¸€í†¤)
   */
  const getAudioContext = useCallback((): AudioContext => {
    if (!audioContextRef.current) {
      audioContextRef.current = getSharedAudioContext();

      // GainNode ìƒì„± (ë³¼ë¥¨ ì¡°ì ˆìš©) - ì´ í›… ì „ìš©
      gainNodeRef.current = audioContextRef.current.createGain();
      gainNodeRef.current.connect(audioContextRef.current.destination);
      gainNodeRef.current.gain.value = volume;
    }
    return audioContextRef.current;
  }, [volume]);

  /**
   * URLì—ì„œ AudioBuffer ë¡œë“œ
   */
  const fetchAudioBuffer = useCallback(async (
    context: AudioContext,
    url: string
  ): Promise<AudioBuffer> => {
    const response = await fetch(url);
    if (!response.ok) {
      throw new Error(`Failed to fetch audio: ${url}`);
    }
    const arrayBuffer = await response.arrayBuffer();
    return context.decodeAudioData(arrayBuffer);
  }, []);

  /**
   * ì—¬ëŸ¬ AudioBufferë¥¼ í•˜ë‚˜ë¡œ í•©ì„±
   * intro + chorusÃ—N + outro
   */
  const combineBuffers = useCallback((
    context: AudioContext,
    intro: AudioBuffer,
    chorus: AudioBuffer,
    outro: AudioBuffer
  ): AudioBuffer => {
    // ì´ ê¸¸ì´ ê³„ì‚°: intro + chorusÃ—N + outro
    const totalLength = intro.length + (chorus.length * chorusRepeat) + outro.length;
    const sampleRate = intro.sampleRate;
    const numberOfChannels = Math.max(intro.numberOfChannels, chorus.numberOfChannels, outro.numberOfChannels);

    // ìƒˆ ë²„í¼ ìƒì„±
    const combined = context.createBuffer(numberOfChannels, totalLength, sampleRate);

    // ê° ì±„ë„ì— ë°ì´í„° ë³µì‚¬
    for (let channel = 0; channel < numberOfChannels; channel++) {
      const outputData = combined.getChannelData(channel);

      // ê° ì±„ë„ë§ˆë‹¤ offsetì„ 0ë¶€í„° ì‹œì‘ (ì´ì „ ë²„ê·¸: offsetì´ ì±„ë„ ê°„ ëˆ„ì ë¨)
      let offset = 0;

      // 1. Intro ë³µì‚¬
      const introData = channel < intro.numberOfChannels
        ? intro.getChannelData(channel)
        : intro.getChannelData(0);
      outputData.set(introData, offset);
      offset += intro.length;

      // 2. Chorus Ã— N ë³µì‚¬
      const chorusData = channel < chorus.numberOfChannels
        ? chorus.getChannelData(channel)
        : chorus.getChannelData(0);
      for (let i = 0; i < chorusRepeat; i++) {
        outputData.set(chorusData, offset);
        offset += chorus.length;
      }

      // 3. Outro ë³µì‚¬
      const outroData = channel < outro.numberOfChannels
        ? outro.getChannelData(channel)
        : outro.getChannelData(0);
      outputData.set(outroData, offset);
      offset += outro.length;
    }

    return combined;
  }, [chorusRepeat]);

  /**
   * í˜„ì¬ ì¬ìƒ ì‹œê°„ ì—…ë°ì´íŠ¸ (requestAnimationFrame)
   * ref ê¸°ë°˜ìœ¼ë¡œ stale closure ë¬¸ì œ í•´ê²°
   */
  const updateCurrentTime = useCallback(() => {
    if (!isPlayingRef.current) return;

    if (!audioContextRef.current) {
      animationFrameRef.current = requestAnimationFrame(updateCurrentTime);
      return;
    }

    const elapsed = audioContextRef.current.currentTime - startTimeRef.current;
    const newTime = pauseOffsetRef.current + elapsed;
    const dur = durationRef.current;

    if (newTime >= dur && dur > 0) {
      setCurrentTime(dur);
      setIsPlaying(false);
      isPlayingRef.current = false;
      pauseOffsetRef.current = 0;
      return;
    }

    setCurrentTime(newTime);
    animationFrameRef.current = requestAnimationFrame(updateCurrentTime);
  }, []);

  /**
   * ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ë° í•©ì„±
   */
  const loadAudio = useCallback(async (urls: AudioUrls): Promise<void> => {
    setIsLoading(true);
    setIsReady(false);
    setCurrentTime(0);
    setDuration(0);
    pauseOffsetRef.current = 0;
    isPlayingRef.current = false;
    setIsPlaying(false);

    // ì´ì „ ì¬ìƒ ì™„ì „ ì •ì§€ ë° ë²„í¼ ì´ˆê¸°í™”
    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.onended = null;
        sourceNodeRef.current.stop();
        sourceNodeRef.current.disconnect();
      } catch {
        // ì´ë¯¸ ì •ì§€ë¨
      }
      sourceNodeRef.current = null;
    }
    combinedBufferRef.current = null;

    try {
      const context = getAudioContext();

      const [introResponse, chorusResponse, outroResponse] = await Promise.all([
        fetch(urls.intro),
        fetch(urls.chorus),
        fetch(urls.outro),
      ]);

      if (!introResponse.ok || !chorusResponse.ok || !outroResponse.ok) {
        throw new Error(`Fetch failed: intro=${introResponse.status}, chorus=${chorusResponse.status}, outro=${outroResponse.status}`);
      }

      const [introArrayBuffer, chorusArrayBuffer, outroArrayBuffer] = await Promise.all([
        introResponse.arrayBuffer(),
        chorusResponse.arrayBuffer(),
        outroResponse.arrayBuffer(),
      ]);

      const [introBuffer, chorusBuffer, outroBuffer] = await Promise.all([
        context.decodeAudioData(introArrayBuffer),
        context.decodeAudioData(chorusArrayBuffer),
        context.decodeAudioData(outroArrayBuffer),
      ]);

      const combined = combineBuffers(context, introBuffer, chorusBuffer, outroBuffer);
      combinedBufferRef.current = combined;
      setDuration(combined.duration);
      setIsReady(true);
    } catch (error) {
      console.error('[loadAudio] Failed:', error);
      setIsReady(false);
    } finally {
      setIsLoading(false);
    }
  }, [getAudioContext, combineBuffers]);

  /**
   * ì¬ìƒ ì‹œì‘ (async - AudioContext resume ëŒ€ê¸°, ref ê¸°ë°˜)
   */
  const play = useCallback(async () => {
    if (!combinedBufferRef.current || !audioContextRef.current) return;

    const context = audioContextRef.current;

    if (context.state === 'suspended') {
      try {
        await context.resume();
      } catch (error) {
        console.error('[play] Failed to resume AudioContext:', error);
        return;
      }
    }

    // ì´ì „ sourceNode ì •ë¦¬
    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.onended = null;
        sourceNodeRef.current.stop();
        sourceNodeRef.current.disconnect();
      } catch {
        // ì´ë¯¸ ì •ì§€ë¨
      }
      sourceNodeRef.current = null;
    }

    // ìƒˆ sourceNode ìƒì„±
    const source = context.createBufferSource();
    source.buffer = combinedBufferRef.current;
    if (gainNodeRef.current) {
      source.connect(gainNodeRef.current);
    } else {
      source.connect(context.destination);
    }

    // ì¬ìƒ ì™„ë£Œ ì‹œ ë°˜ë³µ ì¬ìƒ ì²˜ë¦¬
    source.onended = () => {
      if (isPlayingRef.current && sourceNodeRef.current === source) {
        pauseOffsetRef.current = 0;
        setCurrentTime(0);

        const ctx = audioContextRef.current;
        const buffer = combinedBufferRef.current;
        if (ctx && buffer) {
          const newSource = ctx.createBufferSource();
          newSource.buffer = buffer;
          if (gainNodeRef.current) {
            newSource.connect(gainNodeRef.current);
          } else {
            newSource.connect(ctx.destination);
          }
          newSource.onended = source.onended;
          startTimeRef.current = ctx.currentTime;
          newSource.start(0, 0);
          sourceNodeRef.current = newSource;
        }
      }
    };

    startTimeRef.current = context.currentTime;
    source.start(0, pauseOffsetRef.current);
    sourceNodeRef.current = source;
    isPlayingRef.current = true;
    setIsPlaying(true);

    if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
    }

    const tick = () => {
      if (!isPlayingRef.current) return;

      const ctx = audioContextRef.current;
      if (!ctx) {
        animationFrameRef.current = requestAnimationFrame(tick);
        return;
      }

      const elapsed = ctx.currentTime - startTimeRef.current;
      const newTime = pauseOffsetRef.current + elapsed;
      const dur = durationRef.current;

      if (newTime >= dur && dur > 0) {
        setCurrentTime(dur);
        setIsPlaying(false);
        isPlayingRef.current = false;
        pauseOffsetRef.current = 0;
        return;
      }

      setCurrentTime(newTime);
      animationFrameRef.current = requestAnimationFrame(tick);
    };

    animationFrameRef.current = requestAnimationFrame(tick);
  }, []);

  /**
   * ì¼ì‹œì •ì§€ (ë” ì•ˆì „í•˜ê²Œ)
   */
  const pause = useCallback(() => {
    console.log('ğŸµ [WebAudio.pause] í˜¸ì¶œë¨, isPlaying:', isPlayingRef.current);

    if (!audioContextRef.current) {
      console.log('ğŸµ [WebAudio.pause] audioContext ì—†ìŒ');
      return;
    }

    if (isPlayingRef.current) {
      const elapsed = audioContextRef.current.currentTime - startTimeRef.current;
      pauseOffsetRef.current += elapsed;
    }

    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.onended = null;
        sourceNodeRef.current.stop();
        sourceNodeRef.current.disconnect();
        console.log('ğŸµ [WebAudio.pause] sourceNode ì •ì§€ë¨');
      } catch {
        console.log('ğŸµ [WebAudio.pause] sourceNode ì´ë¯¸ ì •ì§€ë¨');
      }
      sourceNodeRef.current = null;
    }

    setIsPlaying(false);
    isPlayingRef.current = false;
    console.log('ğŸµ [WebAudio.pause] ì™„ë£Œ');
  }, []);

  /**
   * íŠ¹ì • ìœ„ì¹˜ë¡œ ì´ë™ (ref ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ)
   */
  const seek = useCallback((time: number) => {
    const dur = durationRef.current;
    const clampedTime = Math.max(0, Math.min(time, dur));

    pauseOffsetRef.current = clampedTime;
    setCurrentTime(clampedTime);

    if (isPlayingRef.current && combinedBufferRef.current && audioContextRef.current) {
      if (sourceNodeRef.current) {
        try {
          sourceNodeRef.current.onended = null;
          sourceNodeRef.current.stop();
          sourceNodeRef.current.disconnect();
        } catch {
          // ì´ë¯¸ ì •ì§€ë¨
        }
        sourceNodeRef.current = null;
      }

      const context = audioContextRef.current;
      const source = context.createBufferSource();
      source.buffer = combinedBufferRef.current;
      if (gainNodeRef.current) {
        source.connect(gainNodeRef.current);
      } else {
        source.connect(context.destination);
      }

      source.onended = () => {
        if (isPlayingRef.current && sourceNodeRef.current === source) {
          pauseOffsetRef.current = 0;
          setCurrentTime(0);

          const ctx = audioContextRef.current;
          const buffer = combinedBufferRef.current;
          if (ctx && buffer) {
            const newSource = ctx.createBufferSource();
            newSource.buffer = buffer;
            if (gainNodeRef.current) {
              newSource.connect(gainNodeRef.current);
            } else {
              newSource.connect(ctx.destination);
            }
            newSource.onended = source.onended;
            startTimeRef.current = ctx.currentTime;
            newSource.start(0, 0);
            sourceNodeRef.current = newSource;
          }
        }
      };

      startTimeRef.current = context.currentTime;
      source.start(0, clampedTime);
      sourceNodeRef.current = source;
    }
  }, []);

  /**
   * ì •ì§€ + ì²˜ìŒìœ¼ë¡œ (ë” ì•ˆì „í•˜ê²Œ)
   */
  const stop = useCallback(() => {
    if (sourceNodeRef.current) {
      try {
        sourceNodeRef.current.onended = null;
        sourceNodeRef.current.stop();
        sourceNodeRef.current.disconnect();
      } catch {
        // ì´ë¯¸ ì •ì§€ë¨
      }
      sourceNodeRef.current = null;
    }

    pauseOffsetRef.current = 0;
    setCurrentTime(0);
    setIsPlaying(false);
    isPlayingRef.current = false;
  }, []);

  /**
   * ë³¼ë¥¨ ì„¤ì • (0~1 ë²”ìœ„)
   */
  const setVolume = useCallback((value: number) => {
    const clampedVolume = Math.max(0, Math.min(1, value));
    setVolumeState(clampedVolume);

    if (gainNodeRef.current && audioContextRef.current) {
      gainNodeRef.current.gain.setTargetAtTime(
        clampedVolume,
        audioContextRef.current.currentTime,
        0.015
      );
    }
  }, []);

  // currentTime ì—…ë°ì´íŠ¸ effect
  useEffect(() => {
    if (isPlaying) {
      animationFrameRef.current = requestAnimationFrame(updateCurrentTime);
    } else if (animationFrameRef.current) {
      cancelAnimationFrame(animationFrameRef.current);
      animationFrameRef.current = null;
    }

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, [isPlaying, updateCurrentTime]);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      if (sourceNodeRef.current) {
        try {
          sourceNodeRef.current.onended = null;
          sourceNodeRef.current.stop();
          sourceNodeRef.current.disconnect();
        } catch {
          // ì´ë¯¸ ì •ì§€ë¨
        }
        sourceNodeRef.current = null;
      }

      if (gainNodeRef.current) {
        try {
          gainNodeRef.current.disconnect();
        } catch {
          // ì´ë¯¸ ì—°ê²° í•´ì œë¨
        }
        gainNodeRef.current = null;
      }

      // ê³µìœ  AudioContextëŠ” ë‹«ì§€ ì•ŠìŒ - refë§Œ ì´ˆê¸°í™”
      audioContextRef.current = null;

      combinedBufferRef.current = null;
    };
  }, []);

  return {
    isLoading,
    isReady,
    isPlaying,
    currentTime,
    duration,
    volume,
    loadAudio,
    play,
    pause,
    seek,
    stop,
    setVolume,
  };
}

export default useWebAudio;
