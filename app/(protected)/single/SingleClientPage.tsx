'use client';

import { useState, useEffect, useCallback, useMemo, useRef } from 'react';
import { useRouter } from 'next/navigation';
import { ChevronLeft } from 'lucide-react';
import SingleScore from '@/components/single/SingleScore';
import SinglePlayerBar from '@/components/single/SinglePlayerBar';
import SingleController from '@/components/single/SingleController';
import RecordingCompleteModal from '@/components/single/RecordingCompleteModal';
import { useWebAudio } from '@/hooks/useWebAudio';
import { useMetronome } from '@/hooks/useMetronome';
import { useRecorder } from '@/hooks/useRecorder';
import { useToast } from '@/contexts/ToastContext';
import { uploadJamRecording } from '@/lib/jamStorage';
import { getSharedAudioContext, resumeAudioContext } from '@/hooks/useAudioContext';
import { useRecordingStore } from '@/stores/recordingStore';
import { DEFAULT_SONG } from '@/data/songs';
import { InputInstrument, OutputInstrument, DEFAULT_INPUT_INSTRUMENT, DEFAULT_OUTPUT_INSTRUMENT } from '@/types/instrument';

// ê³¡ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¤ê¸°
const CURRENT_SONG = DEFAULT_SONG;
const TEST_AUDIO_URLS = CURRENT_SONG.audioUrls;
const songSections = CURRENT_SONG.sections;
const SONG_META = CURRENT_SONG.meta;

const calculateMeasureDuration = (bpm: number, timeSignature: string): number => {
    const [beatsPerMeasure] = timeSignature.split('/').map(Number);
    return (60 / bpm) * beatsPerMeasure;
};

export default function SingleClientPage() {
    const router = useRouter();
    const { showToast } = useToast();
    const [selectedMeasures, setSelectedMeasures] = useState<{ start: number; end: number } | null>(null);
    const [isPlaying, setIsPlaying] = useState(false);
    const [currentTime, setCurrentTime] = useState(0);
    const [isJamming, setIsJamming] = useState(false);
    const [jamOnlyMode, setJamOnlyMode] = useState(false);
    const [metronomeOn, setMetronomeOn] = useState(false);
    const [pressedKey, setPressedKey] = useState<string | null>(null);
    const [inputInstrument, setInputInstrument] = useState<InputInstrument>(DEFAULT_INPUT_INSTRUMENT);
    const [outputInstrument, setOutputInstrument] = useState<OutputInstrument>(DEFAULT_OUTPUT_INSTRUMENT);

    // START JAM ê´€ë ¨ ìƒíƒœ
    const [isCountingDown, setIsCountingDown] = useState(false);
    const [countdown, setCountdown] = useState<number | null>(null);
    const originalPositionRef = useRef<number>(0); // Rí‚¤ ëˆ„ë¥´ê¸° ì „ ìœ„ì¹˜ ì €ì¥
    const countdownAnimationRef = useRef<number | null>(null);

    // ê³¡ ì¢…ë£Œ ì‹œ ëª¨ë‹¬ ìƒíƒœ
    const [showCompleteModal, setShowCompleteModal] = useState(false);

    // Recording state from useRecorder
    const recorder = useRecorder({
        onError: (error) => showToast('error', error),
        onStateChange: () => {} // ë””ë²„ê·¸ ë¡œê·¸ ì œê±°
    });

    const webAudio = useWebAudio({ chorusRepeat: 1 });
    const webAudioRef = useRef(webAudio);
    webAudioRef.current = webAudio;

    const metronome = useMetronome({ bpm: SONG_META.bpm });

    const measureDuration = useMemo(() => calculateMeasureDuration(SONG_META.bpm, SONG_META.time_signature), []);
    const totalMeasures = useMemo(() => songSections.reduce((acc, s) => acc + s.measures.length, 0), []);
    const duration = webAudio.isReady ? webAudio.duration : totalMeasures * measureDuration;

    const { introEndTime, jamSectionRange } = useMemo(() => {
        let accumulatedMeasures = 0;
        let jamStart = 0;
        let jamEnd = 0;
        let jamStartMeasure = 0;
        let jamEndMeasure = 0;

        for (const section of songSections) {
            const sectionStart = accumulatedMeasures;
            accumulatedMeasures += section.measures.length;

            if (section.isJamSection) {
                jamStart = sectionStart * measureDuration;
                jamEnd = accumulatedMeasures * measureDuration;
                jamStartMeasure = sectionStart + 1; // 1-based
                jamEndMeasure = accumulatedMeasures;
            }
        }

        return {
            introEndTime: (songSections[0].measures.length) * measureDuration,
            jamSectionRange: {
                startTime: jamStart,
                endTime: jamEnd,
                startMeasure: jamStartMeasure,
                endMeasure: jamEndMeasure
            }
        };
    }, [measureDuration]);

    const playerBarSections = useMemo(() => {
        let accumulatedMeasures = 0;
        return songSections.map(section => {
            const startTime = accumulatedMeasures * measureDuration;
            accumulatedMeasures += section.measures.length;
            const endTime = accumulatedMeasures * measureDuration;
            return { id: section.id, label: section.label, startTime, endTime, isJamSection: section.isJamSection };
        });
    }, [measureDuration]);

    const currentSectionIndex = useMemo(() => {
        let accumulatedTime = 0;
        for (let i = 0; i < songSections.length; i++) {
            if (currentTime < accumulatedTime + (songSections[i].measures.length * measureDuration)) return i;
            accumulatedTime += songSections[i].measures.length * measureDuration;
        }
        return songSections.length - 1;
    }, [currentTime, measureDuration]);

    const currentMeasureInSection = useMemo(() => {
        let accumulatedTime = 0;
        for (let i = 0; i < currentSectionIndex; i++) {
            accumulatedTime += songSections[i].measures.length * measureDuration;
        }
        return Math.floor((currentTime - accumulatedTime) / measureDuration);
    }, [currentTime, currentSectionIndex, measureDuration]);

    const measureProgress = useMemo(() => {
        const timeInSection = currentTime - playerBarSections[currentSectionIndex].startTime;
        return (timeInSection % measureDuration) / measureDuration;
    }, [currentTime, currentSectionIndex, playerBarSections, measureDuration]);
    
    const currentSection = songSections[currentSectionIndex];
    const globalMeasure = useMemo(() => {
        let total = 0;
        for (let i = 0; i < currentSectionIndex; i++) {
            total += songSections[i].measures.length;
        }
        return total + currentMeasureInSection + 1;
    }, [currentSectionIndex, currentMeasureInSection]);

    // í˜„ì¬ ë§ˆë””ì˜ ì‹œì‘ ì‹œê°„ì„ ê³„ì‚° (ë§ˆë”” ê²½ê³„ì— ë§ì¶¤)
    const currentMeasureStartTime = useMemo(() => {
        return (globalMeasure - 1) * measureDuration;
    }, [globalMeasure, measureDuration]);

    const formatTime = (seconds: number) => `${Math.floor(seconds / 60)}:${Math.floor(seconds % 60).toString().padStart(2, "0")}`;

    // ë…¹ìŒ ì¤‘ì—ëŠ” ë§ˆë”” ì„ íƒ ì°¨ë‹¨
    const handleSelectionChange = useCallback((selection: { start: number; end: number } | null) => {
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        setSelectedMeasures(selection);
    }, [isJamming, showToast]);

    useEffect(() => { webAudioRef.current.loadAudio(TEST_AUDIO_URLS); }, []);

    // ì»´í¬ë„ŒíŠ¸ ë§ˆìš´íŠ¸ ì‹œ ì´ì „ ë…¹ìŒ ë°ì´í„° ì´ˆê¸°í™” (Feedback í˜ì´ì§€ì—ì„œ ëŒì•„ì˜¬ ë•Œ)
    useEffect(() => {
        // ì´ì „ ë…¹ìŒì´ ìˆìœ¼ë©´ ì´ˆê¸°í™”
        if (recorder.segments.length > 0 || recorder.state !== 'idle') {
            console.log('ğŸ¤ [Single Mount] ì´ì „ ë…¹ìŒ ë°ì´í„° ì´ˆê¸°í™”');
            recorder.resetRecording();
        }
    // eslint-disable-next-line react-hooks/exhaustive-deps
    }, []); // ë§ˆìš´íŠ¸ ì‹œ 1íšŒë§Œ ì‹¤í–‰

    // webAudio.currentTimeì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ í•­ìƒ ë°˜ì˜ (ì¬ìƒ ì¤‘ì´ë“  ì•„ë‹ˆë“ )
    useEffect(() => { setCurrentTime(webAudio.currentTime); }, [webAudio.currentTime]);

    // ê³¡ ì¢…ë£Œ ê°ì§€: ë…¹ìŒì´ ìˆìœ¼ë©´ ëª¨ë‹¬ í‘œì‹œ
    // JAM Only ëª¨ë“œ: Chorus ëì—ì„œ ì¢…ë£Œ
    // ì¼ë°˜ ëª¨ë“œ: Outro ëì—ì„œ ì¢…ë£Œ
    const prevCurrentTimeRef = useRef(0);
    useEffect(() => {
        if (!webAudio.isPlaying || isJamming || isCountingDown) {
            prevCurrentTimeRef.current = currentTime;
            return;
        }

        const hasRecording = recorder.state === 'recorded' && recorder.segments.length > 0;
        if (!hasRecording) {
            prevCurrentTimeRef.current = currentTime;
            return;
        }

        // JAM Only ëª¨ë“œ: Chorus ëì— ë„ë‹¬
        if (jamOnlyMode) {
            const chorusEndTime = jamSectionRange.endTime;
            const reachedChorusEnd = prevCurrentTimeRef.current < chorusEndTime && currentTime >= chorusEndTime - 0.1;

            if (reachedChorusEnd) {
                console.log('ğŸµ [JAM Only ì¢…ë£Œ] Chorus ë ë„ë‹¬ - ëª¨ë‹¬ í‘œì‹œ');
                webAudio.pause();
                metronome.stop();
                setIsPlaying(false);
                setShowCompleteModal(true);
            }
        } else {
            // ì¼ë°˜ ëª¨ë“œ: ê³¡ ëì— ë„ë‹¬
            const reachedEnd = webAudio.duration > 0 &&
                              prevCurrentTimeRef.current < webAudio.duration - 0.5 &&
                              currentTime >= webAudio.duration - 0.5;

            if (reachedEnd) {
                console.log('ğŸµ [ê³¡ ì¢…ë£Œ] Outro ë ë„ë‹¬ - ëª¨ë‹¬ í‘œì‹œ');
                webAudio.pause();
                metronome.stop();
                setIsPlaying(false);
                setShowCompleteModal(true);
            }
        }

        prevCurrentTimeRef.current = currentTime;
    }, [webAudio, currentTime, recorder.state, recorder.segments.length, isJamming, isCountingDown, metronome, jamOnlyMode, jamSectionRange.endTime]);

    // ì¬ìƒ ì¤‘ ë…¹ìŒ êµ¬ê°„ ì§„ì…/ì „í™˜ ì‹œ ë…¹ìŒ ì¬ìƒ ì‹œì‘ + ë³¼ë¥¨ ì¡°ì ˆ
    const prevSegmentIdRef = useRef<string | null>(null);
    useEffect(() => {
        // isPlayingì´ falseë©´ ë…¹ìŒ ì¬ìƒ ì •ì§€ (pause í˜¸ì¶œ ì§í›„ ë°˜ì˜)
        if (!isPlaying) {
            if (prevSegmentIdRef.current) {
                recorder.pauseRecordings();
            }
            prevSegmentIdRef.current = null;
            return;
        }

        if (!webAudio.isPlaying || recorder.state !== 'recorded' || recorder.segments.length === 0) {
            prevSegmentIdRef.current = null;
            return;
        }

        // í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ì„¸ê·¸ë¨¼íŠ¸ ì°¾ê¸°
        const currentSegment = recorder.segments.find(
            seg => currentTime >= seg.startTime && currentTime <= seg.endTime
        );
        const currentSegmentId = currentSegment?.id || null;

        // ì„¸ê·¸ë¨¼íŠ¸ ì§„ì… ë˜ëŠ” ì „í™˜ ê°ì§€
        if (currentSegmentId && currentSegmentId !== prevSegmentIdRef.current) {
            console.log('ğŸµ Segment change:', prevSegmentIdRef.current, 'â†’', currentSegmentId, 'at', currentTime);
            // ì´ì „ ì„¸ê·¸ë¨¼íŠ¸ ì¬ìƒ ì¤‘ì§€ í›„ ìƒˆ ì„¸ê·¸ë¨¼íŠ¸ ì¬ìƒ
            recorder.pauseRecordings();
            webAudio.setVolume(0.3); // ì›ê³¡ ë³¼ë¥¨ ë‚®ì¶¤
            recorder.playRecordingsAtTime(currentTime);
        }
        // ëª¨ë“  ë…¹ìŒ êµ¬ê°„ì„ ë²—ì–´ë‚¬ì„ ë•Œ ì •ì§€
        else if (!currentSegmentId && prevSegmentIdRef.current) {
            console.log('ğŸµ Left all recording ranges, pausing playback');
            webAudio.setVolume(1.0); // ì›ê³¡ ë³¼ë¥¨ ë³µêµ¬
            recorder.pauseRecordings();
        }

        prevSegmentIdRef.current = currentSegmentId;
    }, [currentTime, webAudio, recorder, isPlaying]);

    // Recording ranges derived from recorder segments (ë³µìˆ˜ ë…¹ìŒ ì§€ì›)
    const recordedRanges = useMemo(() => {
        return recorder.segments.map(seg => ({
            start: seg.startTime,
            end: seg.endTime
        }));
    }, [recorder.segments]);

    // Check if current position is within JAM section
    const isInJamSection = useMemo(() => {
        return currentTime >= jamSectionRange.startTime && currentTime < jamSectionRange.endTime;
    }, [currentTime, jamSectionRange]);

    const handlePlayPause = useCallback(async () => {
        console.log('ğŸµ handlePlayPause called', {
            webAudioIsPlaying: webAudio.isPlaying,
            localIsPlaying: isPlaying,
            recorderState: recorder.state,
            segmentCount: recorder.segments.length,
            currentTime
        });

        // webAudio.isPlaying ë˜ëŠ” ë¡œì»¬ isPlaying ì¤‘ í•˜ë‚˜ë¼ë„ trueë©´ ì •ì§€
        if (webAudio.isPlaying || isPlaying) {
            console.log('ğŸµ [handlePlayPause] ì •ì§€ ì²˜ë¦¬ ì‹œì‘');
            webAudio.pause();
            metronome.stop();
            recorder.pauseRecordings(); // ë…¹ìŒ ì¬ìƒë„ ì¼ì‹œì •ì§€
            setIsPlaying(false);
            console.log('ğŸµ [handlePlayPause] ì •ì§€ ì²˜ë¦¬ ì™„ë£Œ');
        } else {
            await webAudio.play();
            // ë©”íŠ¸ë¡œë†ˆ: í•­ìƒ ì‹œì‘í•˜ë˜ í˜„ì¬ ìœ„ì¹˜ë¡œ ë™ê¸°í™”, ìŒì†Œê±° ìƒíƒœ ìœ ì§€
            metronome.seekTo(currentTime);
            await metronome.start();
            // ë…¹ìŒì´ ì™„ë£Œëœ ìƒíƒœì´ê³ , í˜„ì¬ ì‹œê°„ì´ ë…¹ìŒ êµ¬ê°„ ë‚´ë¼ë©´ ë…¹ìŒë„ ì¬ìƒ
            const currentSegment = recorder.segments.find(
                seg => currentTime >= seg.startTime && currentTime <= seg.endTime
            );
            if (recorder.state === 'recorded' && currentSegment) {
                console.log('ğŸµ Starting recording playback at', currentTime, 'segment:', currentSegment.id);
                webAudio.setVolume(0.3);
                await recorder.playRecordingsAtTime(currentTime);
                prevSegmentIdRef.current = currentSegment.id; // í˜„ì¬ ì„¸ê·¸ë¨¼íŠ¸ ID ì €ì¥
            }
            setIsPlaying(true);
        }
    }, [webAudio, metronome, recorder, currentTime, isPlaying]);

    const handleToggleJam = useCallback(async () => {
        console.log('ğŸ¤ handleToggleJam called', { isJamming, isInJamSection, currentTime, jamSectionRange });

        if (isJamming) {
            // STOP JAM: ë…¹ìŒ ì¢…ë£Œ - í˜„ì¬ ë§ˆë”” ë ì‹œê°„ìœ¼ë¡œ ë§ì¶¤
            const currentMeasureEndTime = currentMeasureStartTime + measureDuration;
            console.log('ğŸ¤ Stopping recording at measure end:', {
                currentTime,
                currentMeasureEndTime,
                globalMeasure
            });

            setIsJamming(false);
            await recorder.stopRecording(currentMeasureEndTime, globalMeasure);
            webAudio.pause();
            webAudio.setVolume(1); // ë³¼ë¥¨ ë³µêµ¬
            metronome.stop();
            setIsPlaying(false);

            showToast('success', 'ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤');
        } else {
            // START JAM: JAM ì„¹ì…˜ì¸ì§€ í™•ì¸
            if (!isInJamSection) {
                console.log('ğŸ¤ Not in JAM section, showing toast');
                showToast('warning', 'JAM ì„¹ì…˜ì—ì„œë§Œ ë…¹ìŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
                return;
            }

            // í˜„ì¬ ë§ˆë””ì— ê²¹ì¹˜ëŠ” ê¸°ì¡´ ë…¹ìŒì´ ìˆëŠ”ì§€ í™•ì¸
            const overlapping = recorder.getOverlappingSegment(globalMeasure, globalMeasure);
            if (overlapping) {
                const confirmed = window.confirm(
                    `ë§ˆë”” ${globalMeasure}ë¶€í„° ë…¹ìŒí•©ë‹ˆë‹¤. ê¸°ì¡´ ë…¹ìŒ(${overlapping.startMeasure}-${overlapping.endMeasure})ì€ ë§ˆë”” ${globalMeasure}ë¶€í„° ë®ì–´ì”ë‹ˆë‹¤.`
                );
                if (!confirmed) return;
                // ìƒˆ ë…¹ìŒì´ ê¸°ì¡´ ê²¹ì¹˜ëŠ” ë¶€ë¶„ë§Œ ë®ì–´ì“°ê³ , ì´ì „ ë§ˆë””ëŠ” ìœ ì§€ë¨
            }

            // ê¶Œí•œ ìš”ì²­
            const hasPermission = await recorder.requestPermission();
            if (!hasPermission) return;

            // ë…¹ìŒ ì‹œì‘ - ë§ˆë”” ê²½ê³„ì— ë§ì¶¤ (currentMeasureStartTime ì‚¬ìš©)
            console.log('ğŸ¤ Starting recording at measure boundary:', {
                currentTime,
                currentMeasureStartTime,
                globalMeasure
            });
            const started = await recorder.startRecording(currentMeasureStartTime, globalMeasure);
            if (!started) return;

            setIsJamming(true);

            // ì˜¤ë””ì˜¤ë„ ë§ˆë”” ê²½ê³„ë¡œ seek í›„ ì¬ìƒ (ë³¼ë¥¨ ë‚®ì¶¤)
            webAudio.seek(currentMeasureStartTime);
            setCurrentTime(currentMeasureStartTime);
            webAudio.setVolume(0.3);
            await webAudio.play();
            // ë©”íŠ¸ë¡œë†ˆ: í•­ìƒ ì‹œì‘í•˜ë˜ í˜„ì¬ ìœ„ì¹˜ë¡œ ë™ê¸°í™”
            metronome.seekTo(currentMeasureStartTime);
            await metronome.start();
            setIsPlaying(true);
        }
    }, [isJamming, recorder, currentTime, currentMeasureStartTime, measureDuration, globalMeasure, jamSectionRange, isInJamSection, webAudio, metronome, showToast]);

    const handleTimeChange = useCallback((newTime: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” seek ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }

        let clampedTime = Math.max(0, Math.min(newTime, duration));

        // JAM Only ëª¨ë“œ: Chorus ë²”ìœ„ë¡œ ì œí•œ
        if (jamOnlyMode) {
            if (clampedTime < jamSectionRange.startTime || clampedTime >= jamSectionRange.endTime) {
                showToast('info', 'JAMë§Œ ë“£ê¸°ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤');
                // ë²”ìœ„ ë°– í´ë¦­ ì‹œ í˜„ì¬ ìœ„ì¹˜ ìœ ì§€ (ì´ë™í•˜ì§€ ì•ŠìŒ)
                return;
            }
        }

        // ë…¹ìŒ ì¬ìƒ ì¤‘ì´ë©´ ì¼ì‹œì •ì§€ í›„ ìƒˆ ìœ„ì¹˜ì—ì„œ ì¬ì‹œì‘
        if (recorder.state === 'recorded') {
            recorder.pauseRecordings();

            // ë§Œì•½ ì¬ìƒ ì¤‘ì´ê³  ìƒˆ ìœ„ì¹˜ê°€ ë…¹ìŒ êµ¬ê°„ ë‚´ë¼ë©´, ë…¹ìŒë„ ìƒˆ ìœ„ì¹˜ì—ì„œ ì¬ìƒ
            if (webAudio.isPlaying && recorder.hasRecordingAt(clampedTime)) {
                webAudio.setVolume(0.3);
                // ì•½ê°„ì˜ ë”œë ˆì´ í›„ ì¬ìƒ ì‹œì‘ (seek ì™„ë£Œ ëŒ€ê¸°)
                setTimeout(() => {
                    recorder.playRecordingsAtTime(clampedTime);
                }, 50);
            } else if (!recorder.hasRecordingAt(clampedTime)) {
                // ë…¹ìŒ êµ¬ê°„ ë°–ìœ¼ë¡œ ì´ë™í•˜ë©´ ë³¼ë¥¨ ë³µêµ¬
                webAudio.setVolume(1.0);
            }
        }

        webAudio.seek(clampedTime);
        metronome.seekTo(clampedTime); // ë©”íŠ¸ë¡œë†ˆë„ ë™ê¸°í™”
        setCurrentTime(clampedTime);
    }, [duration, webAudio, isJamming, showToast, recorder, metronome, jamOnlyMode, jamSectionRange]);

    const handleSeekByMeasures = useCallback((offset: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” seek ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        const newTime = webAudio.currentTime + (offset * measureDuration);
        handleTimeChange(newTime);
    }, [webAudio, measureDuration, handleTimeChange, isJamming, showToast]);

    // ë§ˆë”” í´ë¦­ ì‹œ í•´ë‹¹ ë§ˆë”” ì²˜ìŒìœ¼ë¡œ ì´ë™
    const handleMeasureClick = useCallback((globalMeasureIndex: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™ ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        // globalMeasureIndexëŠ” 0-basedì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        const targetTime = globalMeasureIndex * measureDuration;
        handleTimeChange(targetTime);
    }, [measureDuration, handleTimeChange, isJamming, showToast]);

    const handleToggleJamOnly = useCallback((enabled: boolean) => {
        setJamOnlyMode(enabled);
        if (enabled && webAudio.currentTime < introEndTime) {
            handleTimeChange(introEndTime);
        }
    }, [webAudio, introEndTime, handleTimeChange]);

    const handleToggleMetronome = useCallback((enabled: boolean) => {
        setMetronomeOn(enabled);
        // ìŒì†Œê±°ë§Œ í† ê¸€ (ë©”íŠ¸ë¡œë†ˆì€ ì¬ìƒ ì¤‘ì¼ ë•Œ ì´ë¯¸ ì‹¤í–‰ ì¤‘)
        metronome.setMuted(!enabled);
        // ì¬ìƒ ì¤‘ì´ ì•„ë‹ ë•Œ ë©”íŠ¸ë¡œë†ˆ ì¼œë©´ í˜„ì¬ ìœ„ì¹˜ë¡œ ë™ê¸°í™”
        if (enabled && !metronome.isRunning) {
            metronome.seekTo(currentTime);
        }
    }, [metronome, currentTime]);

    // Zustand storeì—ì„œ setRecording ê°€ì ¸ì˜¤ê¸°
    const setRecording = useRecordingStore((state) => state.setRecording);

    // ì¢…ë£Œ(Feedback) ë²„íŠ¼ - storeì— ë…¹ìŒ ì €ì¥ í›„ Feedback í˜ì´ì§€ë¡œ ì´ë™
    const handleFinish = useCallback(() => {
        if (recorder.state !== 'recorded' || recorder.segments.length === 0) {
            showToast('warning', 'ë…¹ìŒì´ ì—†ìŠµë‹ˆë‹¤');
            return;
        }

        // ë…¹ìŒ ë°ì´í„°ë¥¼ storeì— ì €ì¥ (ë§ˆì»¤ ê¸°ë°˜ - preroll ì—†ìŒ)
        const firstSegment = recorder.segments[0];
        if (firstSegment && recorder.recordingRange) {
            // ì €ì¥ ì§ì „ í™•ì¸ ë¡œê·¸
            console.log('ğŸ’¾ ì €ì¥ ì§ì „:', {
                blobSize: firstSegment.blob.size,
                blobType: firstSegment.blob.type,
                range: `${recorder.recordingRange.startMeasure}-${recorder.recordingRange.endMeasure}`,
                note: 'ë§ˆì»¤ ê¸°ë°˜ ì¶”ì¶œ ì™„ë£Œ - blobType=audio/wav'
            });
            setRecording(firstSegment.blob, recorder.recordingRange, 0, inputInstrument, outputInstrument);
        }

        // Feedback í˜ì´ì§€ë¡œ ì´ë™
        router.push('/single/feedback');
    }, [recorder, showToast, router, setRecording, inputInstrument, outputInstrument]);

    // ==========================================
    // START JAM (Rí‚¤) í”Œë¡œìš° - AudioContext ê¸°ë°˜ ì¹´ìš´íŠ¸ë‹¤ìš´
    // ==========================================

    /**
     * 2ë§ˆë”” ì „ ë§ˆë”” ë²ˆí˜¸ ê³„ì‚° (ë¬´ì¡°ê±´ 2ë§ˆë”” ì „, ìµœì†Œ 1ë²ˆ ë§ˆë””)
     */
    const calculateTwoMeasuresBackMeasure = useCallback((measure: number): number => {
        return Math.max(1, measure - 2);
    }, []);

    /**
     * START JAM ì‹œì‘ (Rí‚¤ ëˆ„ë¥¼ ë•Œ)
     * 1. í˜„ì¬ ìœ„ì¹˜ ì €ì¥
     * 2. 2ë§ˆë”” ì „ìœ¼ë¡œ ì´ë™
     * 3. AudioContext ê¸°ë°˜ 3,2,1 ì¹´ìš´íŠ¸ë‹¤ìš´
     * 4. ë…¹ìŒ ì‹œì‘
     */
    const handleStartJam = useCallback(async () => {
        // í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ˆë”” ë²ˆí˜¸ ì§ì ‘ ê³„ì‚° (state ì§€ì—° ë¬¸ì œ ë°©ì§€)
        const currentMeasureNum = Math.floor(currentTime / measureDuration) + 1;

        console.log('ğŸ¤ [handleStartJam] ì‹œì‘', { currentMeasureNum, currentTime, globalMeasure, jamSectionRange });

        // JAM ì„¹ì…˜ì¸ì§€ í™•ì¸ (í˜„ì¬ ë§ˆë”” ê¸°ì¤€, 2ë§ˆë”” ì „ìœ¼ë¡œ ì´ë™í•´ë„ ê´œì°®ìŒ)
        const isCurrentMeasureInJam = currentMeasureNum >= jamSectionRange.startMeasure &&
                                       currentMeasureNum <= jamSectionRange.endMeasure;
        console.log('ğŸ¤ [handleStartJam] JAM ì²´í¬:', { isCurrentMeasureInJam, currentMeasureNum, startMeasure: jamSectionRange.startMeasure, endMeasure: jamSectionRange.endMeasure });

        if (!isCurrentMeasureInJam) {
            showToast('warning', 'JAM ì„¹ì…˜ì—ì„œë§Œ ë…¹ìŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
            return;
        }

        // ê¶Œí•œ ìš”ì²­
        const hasPermission = await recorder.requestPermission();
        console.log('ğŸ¤ [handleStartJam] ê¶Œí•œ:', hasPermission);
        if (!hasPermission) return;

        // í˜„ì¬ ë§ˆë””ì— ê²¹ì¹˜ëŠ” ê¸°ì¡´ ë…¹ìŒì´ ìˆëŠ”ì§€ í™•ì¸
        const overlapping = recorder.getOverlappingSegment(currentMeasureNum, currentMeasureNum);
        if (overlapping) {
            const confirmed = window.confirm(
                `ë§ˆë”” ${currentMeasureNum}ë¶€í„° ë…¹ìŒí•©ë‹ˆë‹¤. ê¸°ì¡´ ë…¹ìŒ(${overlapping.startMeasure}-${overlapping.endMeasure})ì€ ë§ˆë”” ${currentMeasureNum}ë¶€í„° ë®ì–´ì”ë‹ˆë‹¤.`
            );
            if (!confirmed) return;
        }

        // AudioContext ì´ˆê¸°í™”
        await resumeAudioContext();
        const audioContext = getSharedAudioContext();

        // ë…¹ìŒ ì‹œì‘ ì‹œê°„ ê³„ì‚° (ë§ˆë”” ê²½ê³„) - í˜„ì¬ ë§ˆë”” ê¸°ì¤€
        const recordStartMeasure = currentMeasureNum;
        const recordStartTime = (recordStartMeasure - 1) * measureDuration;

        // MediaRecorder ì‹œì‘ (ë§ˆì»¤ ê¸°ë°˜ ë…¹ìŒ)
        const started = await recorder.startRecording(recordStartTime, recordStartMeasure);
        console.log('ğŸ¤ [handleStartJam] startRecording:', started);
        if (!started) return;

        // 1. í˜„ì¬ ìœ„ì¹˜ ì €ì¥
        originalPositionRef.current = currentTime;

        // 2. 2ë§ˆë”” ì „ìœ¼ë¡œ ì´ë™ (ë§ˆë”” ê²½ê³„ì— ë§ì¶¤)
        const targetMeasure = calculateTwoMeasuresBackMeasure(currentMeasureNum);
        const startPos = (targetMeasure - 1) * measureDuration;

        console.log(`ğŸ¤ [START JAM] 2ë§ˆë”” ì „ìœ¼ë¡œ ì´ë™: í˜„ì¬ë§ˆë””=${currentMeasureNum}, ëª©í‘œë§ˆë””=${targetMeasure}, í˜„ì¬ì‹œê°„=${currentTime.toFixed(2)}, ì´ë™ìœ„ì¹˜=${startPos.toFixed(2)}`);

        webAudio.seek(startPos);
        metronome.seekTo(startPos);
        setCurrentTime(startPos);

        // 3. ìŒì› + ë©”íŠ¸ë¡œë†ˆ ì¬ìƒ ì‹œì‘ (ë©”íŠ¸ë¡œë†ˆì€ ê¸°ì¡´ ìƒíƒœ ìœ ì§€)
        webAudio.setVolume(0.3);
        await webAudio.play();
        await metronome.start();
        setIsPlaying(true);
        // ë©”íŠ¸ë¡œë†ˆ ON/OFFëŠ” ê¸°ì¡´ metronomeOn ìƒíƒœ ìœ ì§€
        metronome.setMuted(!metronomeOn);

        // 4. AudioContext ê¸°ë°˜ ì¹´ìš´íŠ¸ë‹¤ìš´ ì‹œì‘
        setIsCountingDown(true);
        const countdownStartTime = audioContext.currentTime;
        const secondsPerBeat = 60 / SONG_META.bpm;

        // ì‹¤ì œ ì´ë™í•œ ë§ˆë”” ìˆ˜ ê³„ì‚°
        const measuresBack = currentMeasureNum - targetMeasure;
        const totalBeatsToWait = measuresBack * 4; // 4/4 ë°•ì ê¸°ì¤€

        console.log(`ğŸ¤ [START JAM] ë…¹ìŒ ì‹œì‘ ì˜ˆì •: ë…¹ìŒì‹œì‘ë§ˆë””=${recordStartMeasure}, ë…¹ìŒì‹œì‘ì‹œê°„=${recordStartTime.toFixed(2)}, ëª©í‘œë§ˆë””=${targetMeasure}, ì´ë™ë§ˆë””ìˆ˜=${measuresBack}, ëŒ€ê¸°ë°•ì=${totalBeatsToWait}`);

        const updateCountdown = () => {
            const elapsed = audioContext.currentTime - countdownStartTime;
            const beatsElapsed = elapsed / secondsPerBeat;
            const beatsRemaining = totalBeatsToWait - beatsElapsed;

            // ë§ˆì§€ë§‰ 4ë°•ì„ 4,3,2,1ë¡œ í‘œì‹œ (ë˜ëŠ” ë‚¨ì€ ë°•ìë§Œí¼)
            if (beatsRemaining > 4) {
                // ì¹´ìš´íŠ¸ë‹¤ìš´ í‘œì‹œ ì•ˆí•¨ (ì•„ì§ ë§ˆì§€ë§‰ ë§ˆë”” ì•„ë‹˜)
                setCountdown(null);
            } else if (beatsRemaining > 3) {
                setCountdown(Math.min(4, Math.ceil(beatsRemaining)));
            } else if (beatsRemaining > 2) {
                setCountdown(3);
            } else if (beatsRemaining > 1) {
                setCountdown(2);
            } else if (beatsRemaining > 0) {
                setCountdown(1);
            } else {
                // ì¹´ìš´íŠ¸ë‹¤ìš´ ì™„ë£Œ â†’ ì‹¤ì œ ë…¹ìŒ ì‹œì‘ ë§ˆì»¤ ì„¤ì •
                setCountdown(null);
                setIsCountingDown(false);
                setIsJamming(true);

                // ì‹¤ì œ ë…¹ìŒ ì‹œì‘ ë§ˆì»¤ ì°ê¸° (blob ë‚´ ìƒëŒ€ ì‹œê°„)
                const actualAudioTime = webAudioRef.current.currentTime;
                recorder.markActualStart();
                showToast('info', 'ë…¹ìŒì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤');

                console.log('ğŸ¤ [START JAM] ë…¹ìŒ ì‹œì‘ ë§ˆì»¤ ì„¤ì •:', {
                    ë…¹ìŒì‹œì‘ì‹œê°„: recordStartTime.toFixed(3),
                    ë…¹ìŒì‹œì‘ë§ˆë””: recordStartMeasure,
                    ì‹¤ì œì˜¤ë””ì˜¤ì‹œê°„: actualAudioTime.toFixed(3),
                    ì°¨ì´: (actualAudioTime - recordStartTime).toFixed(3) + 's'
                });
                return;
            }

            countdownAnimationRef.current = requestAnimationFrame(updateCountdown);
        };

        countdownAnimationRef.current = requestAnimationFrame(updateCountdown);
    }, [
        jamSectionRange, recorder, globalMeasure, currentTime, currentMeasureStartTime,
        measureDuration, webAudio, metronome, showToast, metronomeOn,
        calculateTwoMeasuresBackMeasure
    ]);

    /**
     * START JAM ì·¨ì†Œ (ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ Rí‚¤ ë‹¤ì‹œ ëˆ„ë¥¼ ë•Œ)
     */
    const handleCancelStartJam = useCallback(() => {
        // ì¹´ìš´íŠ¸ë‹¤ìš´ ì·¨ì†Œ
        if (countdownAnimationRef.current) {
            cancelAnimationFrame(countdownAnimationRef.current);
            countdownAnimationRef.current = null;
        }

        setIsCountingDown(false);
        setCountdown(null);

        // ì¬ìƒ ì •ì§€
        webAudio.pause();
        metronome.stop();
        setIsPlaying(false);

        // MediaRecorder ì •ë¦¬ (prepareRecordingìœ¼ë¡œ ì‹œì‘ëœ ë…¹ìŒ ì·¨ì†Œ)
        recorder.resetRecording();

        // ì›ë˜ ìœ„ì¹˜ë¡œ ë³µê·€
        webAudio.seek(originalPositionRef.current);
        metronome.seekTo(originalPositionRef.current);
        setCurrentTime(originalPositionRef.current);
        webAudio.setVolume(1.0);

        showToast('info', 'ë…¹ìŒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤');
        console.log('ğŸ¤ [START JAM] ì·¨ì†Œë¨, ì›ë˜ ìœ„ì¹˜ë¡œ ë³µê·€:', originalPositionRef.current);
    }, [webAudio, metronome, showToast, recorder]);

    /**
     * Rí‚¤ í•¸ë“¤ëŸ¬ (ìƒíƒœì— ë”°ë¼ ë¶„ê¸°)
     */
    const handleRKey = useCallback(async () => {
        if (isJamming) {
            // ë…¹ìŒ ì¤‘ â†’ ë…¹ìŒ ì¢…ë£Œ
            const currentMeasureEndTime = currentMeasureStartTime + measureDuration;
            setIsJamming(false);
            await recorder.stopRecording(currentMeasureEndTime, globalMeasure);
            webAudio.pause();
            webAudio.setVolume(1);
            metronome.stop();
            setIsPlaying(false);
            showToast('success', 'ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤');
        } else if (isCountingDown) {
            // ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ â†’ ì·¨ì†Œ
            handleCancelStartJam();
        } else {
            // ëŒ€ê¸° ì¤‘ â†’ START JAM ì‹œì‘
            await handleStartJam();
        }
    }, [
        isJamming, isCountingDown, currentMeasureStartTime, measureDuration,
        globalMeasure, recorder, webAudio, metronome, showToast,
        handleStartJam, handleCancelStartJam
    ]);

    // ë…¹ìŒ ì¼ì‹œì •ì§€/ì¬ê°œ í•¸ë“¤ëŸ¬
    const handlePauseResumeJamming = useCallback(() => {
        if (recorder.isPaused) {
            // ì¬ê°œ
            recorder.resumeJamming();
            webAudio.play();
            if (metronomeOn) metronome.start();
            setIsPlaying(true);
        } else {
            // ì¼ì‹œì •ì§€
            recorder.pauseJamming();
            webAudio.pause();
            metronome.stop();
            setIsPlaying(false);
        }
    }, [recorder, webAudio, metronome, metronomeOn]);

    useEffect(() => {
        const handleKeyDown = async (e: KeyboardEvent) => {
            if (e.target instanceof HTMLInputElement || e.target instanceof HTMLTextAreaElement) return;
            setPressedKey(e.code);
            switch (e.code) {
                case 'Space':
                    e.preventDefault();
                    // ë…¹ìŒ ì¤‘ì´ë©´ ì¼ì‹œì •ì§€/ì¬ê°œ, ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ì´ë©´ ë¬´ì‹œ
                    if (isCountingDown) {
                        // ì¹´ìš´íŠ¸ë‹¤ìš´ ì¤‘ì—ëŠ” Space ë¬´ì‹œ
                        return;
                    } else if (isJamming) {
                        handlePauseResumeJamming();
                    } else {
                        await handlePlayPause();
                    }
                    break;
                case 'KeyZ': e.preventDefault(); handleSeekByMeasures(-1); break;
                case 'KeyX': e.preventDefault(); handleSeekByMeasures(1); break;
                case 'KeyD': // Dí‚¤ - ë©”íŠ¸ë¡œë†ˆ ON/OFF
                    e.preventDefault();
                    handleToggleMetronome(!metronomeOn);
                    break;
                case 'KeyF': // Fí‚¤ - JAMë§Œ ë“£ê¸° í† ê¸€
                    e.preventDefault();
                    handleToggleJamOnly(!jamOnlyMode);
                    break;
                case 'KeyR': // Rí‚¤ - START JAM (ë…¹ìŒ ì‹œì‘/ì¢…ë£Œ/ì·¨ì†Œ)
                    e.preventDefault();
                    await handleRKey();
                    break;
            }
        };
        const handleKeyUp = () => setPressedKey(null);
        window.addEventListener('keydown', handleKeyDown);
        window.addEventListener('keyup', handleKeyUp);
        return () => {
            window.removeEventListener('keydown', handleKeyDown);
            window.removeEventListener('keyup', handleKeyUp);
        };
    }, [handlePlayPause, handlePauseResumeJamming, handleSeekByMeasures, handleToggleJamOnly, handleToggleMetronome, handleRKey, jamOnlyMode, metronomeOn, isJamming, isCountingDown]);

    // í´ë¦°ì—…
    useEffect(() => {
        return () => {
            webAudioRef.current.stop();
            // ì¹´ìš´íŠ¸ë‹¤ìš´ ì• ë‹ˆë©”ì´ì…˜ ì •ë¦¬
            if (countdownAnimationRef.current) {
                cancelAnimationFrame(countdownAnimationRef.current);
            }
        };
    }, []);

    // í˜ì´ì§€ ì´íƒˆ ê²½ê³  (ë…¹ìŒ ì¤‘ ë˜ëŠ” ì €ì¥ë˜ì§€ ì•Šì€ ë…¹ìŒì´ ìˆì„ ë•Œ)
    useEffect(() => {
        const handleBeforeUnload = (e: BeforeUnloadEvent) => {
            if (isJamming || recorder.audioBlob) {
                e.preventDefault();
                e.returnValue = '';
            }
        };
        window.addEventListener('beforeunload', handleBeforeUnload);
        return () => window.removeEventListener('beforeunload', handleBeforeUnload);
    }, [isJamming, recorder.audioBlob]);

    // ë’¤ë¡œê°€ê¸° ë²„íŠ¼ í•¸ë“¤ëŸ¬ (í™•ì¸ í›„ ì´ë™)
    const handleBack = useCallback(() => {
        if (isJamming || recorder.audioBlob) {
            const confirmed = window.confirm(
                isJamming
                    ? 'ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤. ì •ë§ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?'
                    : 'ì €ì¥ë˜ì§€ ì•Šì€ ë…¹ìŒì´ ìˆìŠµë‹ˆë‹¤. ì •ë§ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?'
            );
            if (!confirmed) return;
        }
        router.back();
    }, [isJamming, recorder.audioBlob, router]);

    // ëª¨ë‹¬: "ë„¤" ë²„íŠ¼ - ì²˜ìŒìœ¼ë¡œ ë¦¬ì…‹í•˜ê³  ë‹¤ì‹œ ì¬ìƒ
    const handleModalReplay = useCallback(() => {
        setShowCompleteModal(false);
        webAudio.seek(0);
        metronome.seekTo(0);
        setCurrentTime(0);
        webAudio.setVolume(1.0);
        // ë°”ë¡œ ì¬ìƒ ì‹œì‘
        webAudio.play();
        metronome.seekTo(0);
        metronome.start();
        setIsPlaying(true);
    }, [webAudio, metronome]);

    // ëª¨ë‹¬: "ì•„ë‹ˆìš”(ì €ì¥)" ë²„íŠ¼ - storeì— ë…¹ìŒ ì €ì¥ í›„ Feedback í˜ì´ì§€ë¡œ ì´ë™
    const handleModalSave = useCallback(() => {
        setShowCompleteModal(false);

        // ë…¹ìŒ ë°ì´í„°ë¥¼ storeì— ì €ì¥ (ë§ˆì»¤ ê¸°ë°˜ - preroll ì—†ìŒ)
        const firstSegment = recorder.segments[0];
        if (firstSegment && recorder.recordingRange) {
            // ì €ì¥ ì§ì „ í™•ì¸ ë¡œê·¸
            console.log('ğŸ’¾ ì €ì¥ ì§ì „ (ëª¨ë‹¬):', {
                blobSize: firstSegment.blob.size,
                blobType: firstSegment.blob.type,
                range: `${recorder.recordingRange.startMeasure}-${recorder.recordingRange.endMeasure}`,
                note: 'ë§ˆì»¤ ê¸°ë°˜ ì¶”ì¶œ ì™„ë£Œ - blobType=audio/wav'
            });
            setRecording(firstSegment.blob, recorder.recordingRange, 0, inputInstrument, outputInstrument);
        }

        // Feedback í˜ì´ì§€ë¡œ ì´ë™
        router.push('/single/feedback');
    }, [router, recorder, setRecording, inputInstrument, outputInstrument]);

    return (
        <div className="flex h-screen w-full flex-col overflow-hidden">
            <div className="mx-auto flex h-full w-full max-w-5xl flex-col overflow-hidden px-8 py-8">
                <div className="flex flex-col gap-2 flex-shrink-0">
                    <div className="flex justify-between items-center text-white">
                        <div className="flex items-center gap-4">
                            <button onClick={handleBack} className="p-2 hover:bg-white/10 rounded-full transition-colors"><ChevronLeft size={24} /></button>
                            <div>
                                <h1 className="text-2xl font-bold leading-none">{SONG_META.title}</h1>
                                <span className="text-sm text-gray-400">{SONG_META.artist}</span>
                            </div>
                        </div>
                        <div className="flex items-center gap-3">
                            {webAudio.isLoading && <div className="flex items-center gap-2 text-xs text-gray-400"><div className="w-3 h-3 border-2 border-gray-400 border-t-transparent rounded-full animate-spin" />ë¡œë”© ì¤‘...</div>}
                            <div className="px-3 py-1 border border-gray-600 rounded-full text-xs font-medium text-gray-300">SINGLE MODE</div>
                        </div>
                    </div>
                </div>

                <div className="flex-1 mt-4 relative min-h-0">
                    <div className="absolute -top-0 left-0 right-0 z-10 px-4 py-3 rounded-t-xl border border-b-0 border-gray-700 bg-[#0F172A]">
                        <div className="flex justify-between items-center text-white">
                            <div className="flex gap-6 text-sm font-mono text-gray-300">
                                <span>{formatTime(currentTime)} / {formatTime(duration)}</span>
                                <span>{currentSection?.label} - {globalMeasure}/{totalMeasures} ë§ˆë””</span>
                                {jamOnlyMode && <span className="text-[#7BA7FF]">JAM ONLY</span>}
                                {metronomeOn && <span className="text-[#FFD166]">â™ª {SONG_META.bpm} BPM</span>}
                            </div>
                            {/* Recording/Processing Status */}
                            <div className="flex items-center gap-3">
                                {recorder.isProcessing && (
                                    <div className="text-sm flex items-center gap-2 text-yellow-400">
                                        <div className="w-3 h-3 border-2 border-yellow-400 border-t-transparent rounded-full animate-spin" />
                                        ì²˜ë¦¬ ì¤‘...
                                    </div>
                                )}
                                {isCountingDown && countdown === -1 && (
                                    <div className="text-sm flex items-center gap-2 text-[#FFD166]">
                                        <div className="w-3 h-3 border-2 border-[#FFD166] border-t-transparent rounded-full animate-spin" />
                                        ì¤€ë¹„ ì¤‘...
                                    </div>
                                )}
                                {isCountingDown && countdown !== null && countdown > 0 && (
                                    <div className="text-2xl font-bold text-[#FFD166] animate-pulse">
                                        {countdown}
                                    </div>
                                )}
                                {isJamming && (
                                    <div className={`text-sm font-bold flex items-center gap-2 text-[#FF7B7B] ${recorder.isPaused ? '' : 'animate-pulse'}`}>
                                        <div className="w-2 h-2 rounded-full bg-[#FF7B7B]" />
                                        {recorder.isPaused ? 'PAUSED' : 'JAMMING'}
                                    </div>
                                )}
                                {recorder.state === 'recorded' && !isJamming && !isCountingDown && (
                                    <div className="text-sm flex items-center gap-2 text-green-400">
                                        <div className="w-2 h-2 rounded-full bg-green-400" />
                                        ë…¹ìŒ ì™„ë£Œ
                                    </div>
                                )}
                            </div>
                        </div>
                    </div>

                    <div className="h-full pt-12 rounded-xl border border-[#FFFFFF]/10 bg-[#FFFFFF]/5 overflow-hidden">
                        <SingleScore
                            sections={songSections}
                            currentSectionIndex={currentSectionIndex}
                            currentMeasure={currentMeasureInSection}
                            measureProgress={measureProgress}
                            selectedMeasures={selectedMeasures}
                            onSelectionChange={handleSelectionChange}
                            onMeasureClick={handleMeasureClick}
                            recordedMeasures={recorder.recordedMeasures}
                        />
                    </div>
                </div>

                <div className="mt-6 flex-shrink-0 rounded-xl border border-[#FFFFFF]/10 bg-[#FFFFFF]/5 p-4 space-y-4">
                    <SinglePlayerBar
                        currentTime={currentTime}
                        duration={duration}
                        sections={playerBarSections}
                        onTimeChange={handleTimeChange}
                        recordedRanges={recordedRanges}
                    />
                    <SingleController
                        isPlaying={isPlaying}
                        onPlayPause={handlePlayPause}
                        onToggleJam={handleRKey}
                        isJamming={isJamming || isCountingDown}
                        onSeekBackward={() => handleSeekByMeasures(-1)}
                        onSeekForward={() => handleSeekByMeasures(1)}
                        jamOnlyMode={jamOnlyMode}
                        onToggleJamOnly={handleToggleJamOnly}
                        metronomeOn={metronomeOn}
                        onToggleMetronome={handleToggleMetronome}
                        onFinish={handleFinish}
                        currentTime={currentTime}
                        duration={duration}
                        pressedKey={pressedKey}
                        hasRecording={recorder.state === 'recorded'}
                        inputInstrument={inputInstrument}
                        onInputInstrumentChange={setInputInstrument}
                        outputInstrument={outputInstrument}
                        onOutputInstrumentChange={setOutputInstrument}
                    />
                </div>
            </div>

            {/* ë…¹ìŒ ì™„ë£Œ ëª¨ë‹¬ */}
            <RecordingCompleteModal
                isOpen={showCompleteModal}
                onReplay={handleModalReplay}
                onSave={handleModalSave}
            />
        </div>
    );
}