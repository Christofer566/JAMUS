'use client';

import { useState, useEffect, useCallback, useMemo, useRef } from 'react';
import { useRouter } from 'next/navigation';
import { ChevronLeft } from 'lucide-react';
import SingleScore from '@/components/single/SingleScore';
import SinglePlayerBar from '@/components/single/SinglePlayerBar';
import SingleController from '@/components/single/SingleController';
import { useWebAudio } from '@/hooks/useWebAudio';
import { useMetronome } from '@/hooks/useMetronome';
import { useRecorder } from '@/hooks/useRecorder';
import { useToast } from '@/contexts/ToastContext';
import { uploadJamRecording } from '@/lib/jamStorage';

const TEST_AUDIO_URLS = {
    intro: "https://hzgfbmdqmhjiomwrkukw.supabase.co/storage/v1/object/public/jamus-audio/autumn-leaves/intro.mp3",
    chorus: "https://hzgfbmdqmhjiomwrkukw.supabase.co/storage/v1/object/public/jamus-audio/autumn-leaves/chorus.mp3",
    outro: "https://hzgfbmdqmhjiomwrkukw.supabase.co/storage/v1/object/public/jamus-audio/autumn-leaves/outro.mp3"
};

const mockSections = [
    { id: 'intro', label: 'Intro', isJamSection: false, measures: Array(8).fill({ chord: 'Cm7' }) },
    { id: 'chorus', label: 'Chorus', isJamSection: true, measures: Array(32).fill({ chord: 'F7' }) },
    { id: 'outro', label: 'Outro', isJamSection: false, measures: Array(8).fill({ chord: 'Gm' }) }
];

const MOCK_SONG = {
    id: 'autumn-leaves', // song ID for storage
    bpm: 142,
    time_signature: '4/4',
    title: "Autumn Leaves",
    artist: "Jazz Standard"
};

const calculateMeasureDuration = (bpm: number, timeSignature: string): number => {
    const [beatsPerMeasure] = timeSignature.split('/').map(Number);
    return (60 / bpm) * beatsPerMeasure;
};

export default function SingleClientPage() {
    const router = useRouter();
    const { showToast } = useToast();
    const [selectedMeasures, setSelectedMeasures] = useState<{ start: number; end: number } | null>(null);
    const [isPlaying, setIsPlaying] = useState(false);
    const [currentTime, setCurrentTime] = useState(0);
    const [isJamming, setIsJamming] = useState(false);
    const [jamOnlyMode, setJamOnlyMode] = useState(false);
    const [metronomeOn, setMetronomeOn] = useState(false);
    const [pressedKey, setPressedKey] = useState<string | null>(null);
    const [isSaving, setIsSaving] = useState(false);

    // Recording state from useRecorder
    const recorder = useRecorder({
        onError: (error) => showToast('error', error),
        onStateChange: (state) => console.log('ğŸ¤ Recording state:', state)
    });

    const webAudio = useWebAudio({ chorusRepeat: 1 });
    const webAudioRef = useRef(webAudio);
    webAudioRef.current = webAudio;

    const metronome = useMetronome({ bpm: MOCK_SONG.bpm });

    const measureDuration = useMemo(() => calculateMeasureDuration(MOCK_SONG.bpm, MOCK_SONG.time_signature), []);
    const totalMeasures = useMemo(() => mockSections.reduce((acc, s) => acc + s.measures.length, 0), []);
    const duration = webAudio.isReady ? webAudio.duration : totalMeasures * measureDuration;

    const { introEndTime, jamSectionRange } = useMemo(() => {
        let accumulatedMeasures = 0;
        let jamStart = 0;
        let jamEnd = 0;
        let jamStartMeasure = 0;
        let jamEndMeasure = 0;

        for (const section of mockSections) {
            const sectionStart = accumulatedMeasures;
            accumulatedMeasures += section.measures.length;

            if (section.isJamSection) {
                jamStart = sectionStart * measureDuration;
                jamEnd = accumulatedMeasures * measureDuration;
                jamStartMeasure = sectionStart + 1; // 1-based
                jamEndMeasure = accumulatedMeasures;
            }
        }

        return {
            introEndTime: (mockSections[0].measures.length) * measureDuration,
            jamSectionRange: {
                startTime: jamStart,
                endTime: jamEnd,
                startMeasure: jamStartMeasure,
                endMeasure: jamEndMeasure
            }
        };
    }, [measureDuration]);

    const playerBarSections = useMemo(() => {
        let accumulatedMeasures = 0;
        return mockSections.map(section => {
            const startTime = accumulatedMeasures * measureDuration;
            accumulatedMeasures += section.measures.length;
            const endTime = accumulatedMeasures * measureDuration;
            return { id: section.id, label: section.label, startTime, endTime, isJamSection: section.isJamSection };
        });
    }, [measureDuration]);

    const currentSectionIndex = useMemo(() => {
        let accumulatedTime = 0;
        for (let i = 0; i < mockSections.length; i++) {
            if (currentTime < accumulatedTime + (mockSections[i].measures.length * measureDuration)) return i;
            accumulatedTime += mockSections[i].measures.length * measureDuration;
        }
        return mockSections.length - 1;
    }, [currentTime, measureDuration]);

    const currentMeasureInSection = useMemo(() => {
        let accumulatedTime = 0;
        for (let i = 0; i < currentSectionIndex; i++) {
            accumulatedTime += mockSections[i].measures.length * measureDuration;
        }
        return Math.floor((currentTime - accumulatedTime) / measureDuration);
    }, [currentTime, currentSectionIndex, measureDuration]);

    const measureProgress = useMemo(() => {
        const timeInSection = currentTime - playerBarSections[currentSectionIndex].startTime;
        return (timeInSection % measureDuration) / measureDuration;
    }, [currentTime, currentSectionIndex, playerBarSections, measureDuration]);
    
    const currentSection = mockSections[currentSectionIndex];
    const globalMeasure = useMemo(() => {
        let total = 0;
        for (let i = 0; i < currentSectionIndex; i++) {
            total += mockSections[i].measures.length;
        }
        return total + currentMeasureInSection + 1;
    }, [currentSectionIndex, currentMeasureInSection]);

    // í˜„ì¬ ë§ˆë””ì˜ ì‹œì‘ ì‹œê°„ì„ ê³„ì‚° (ë§ˆë”” ê²½ê³„ì— ë§ì¶¤)
    const currentMeasureStartTime = useMemo(() => {
        return (globalMeasure - 1) * measureDuration;
    }, [globalMeasure, measureDuration]);

    const formatTime = (seconds: number) => `${Math.floor(seconds / 60)}:${Math.floor(seconds % 60).toString().padStart(2, "0")}`;

    // ë…¹ìŒ ì¤‘ì—ëŠ” ë§ˆë”” ì„ íƒ ì°¨ë‹¨
    const handleSelectionChange = useCallback((selection: { start: number; end: number } | null) => {
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        setSelectedMeasures(selection);
    }, [isJamming, showToast]);

    useEffect(() => { webAudioRef.current.loadAudio(TEST_AUDIO_URLS); }, []);
    useEffect(() => { if (webAudio.isPlaying) setCurrentTime(webAudio.currentTime); }, [webAudio.currentTime, webAudio.isPlaying]);

    // ì¬ìƒ ì¤‘ ë…¹ìŒ êµ¬ê°„ ì§„ì… ì‹œ ë…¹ìŒ ì¬ìƒ ì‹œì‘ + ë³¼ë¥¨ ì¡°ì ˆ
    const prevHasRecordingRef = useRef(false);
    useEffect(() => {
        if (!webAudio.isPlaying || recorder.state !== 'recorded' || recorder.segments.length === 0) {
            prevHasRecordingRef.current = false;
            return;
        }

        const hasRecording = recorder.hasRecordingAt(currentTime);

        // ë…¹ìŒ êµ¬ê°„ì— ì²˜ìŒ ì§„ì…í–ˆì„ ë•Œë§Œ ì¬ìƒ ì‹œì‘
        if (hasRecording && !prevHasRecordingRef.current) {
            console.log('ğŸµ Entered recording range, starting playback at', currentTime);
            webAudio.setVolume(0.3); // ì›ê³¡ ë³¼ë¥¨ ë‚®ì¶¤
            recorder.playRecordingsAtTime(currentTime);
        }
        // ë…¹ìŒ êµ¬ê°„ì„ ë²—ì–´ë‚¬ì„ ë•Œ ì •ì§€
        else if (!hasRecording && prevHasRecordingRef.current) {
            console.log('ğŸµ Left recording range, pausing playback');
            webAudio.setVolume(1.0); // ì›ê³¡ ë³¼ë¥¨ ë³µêµ¬
            recorder.pauseRecordings();
        }

        prevHasRecordingRef.current = hasRecording;
    }, [currentTime, webAudio, recorder]);

    // Recording ranges derived from recorder segments (ë³µìˆ˜ ë…¹ìŒ ì§€ì›)
    const recordedRanges = useMemo(() => {
        return recorder.segments.map(seg => ({
            start: seg.startTime,
            end: seg.endTime
        }));
    }, [recorder.segments]);

    // Check if current position is within JAM section
    const isInJamSection = useMemo(() => {
        return currentTime >= jamSectionRange.startTime && currentTime < jamSectionRange.endTime;
    }, [currentTime, jamSectionRange]);

    const handlePlayPause = useCallback(async () => {
        console.log('ğŸµ handlePlayPause called', {
            isPlaying: webAudio.isPlaying,
            recorderState: recorder.state,
            segmentCount: recorder.segments.length,
            currentTime
        });

        if (webAudio.isPlaying) {
            webAudio.pause();
            metronome.stop();
            recorder.pauseRecordings(); // ë…¹ìŒ ì¬ìƒë„ ì¼ì‹œì •ì§€
            setIsPlaying(false);
        } else {
            await webAudio.play();
            if(metronomeOn) await metronome.start();
            // ë…¹ìŒì´ ì™„ë£Œëœ ìƒíƒœì´ê³ , í˜„ì¬ ì‹œê°„ì´ ë…¹ìŒ êµ¬ê°„ ë‚´ë¼ë©´ ë…¹ìŒë„ ì¬ìƒ
            if (recorder.state === 'recorded' && recorder.hasRecordingAt(currentTime)) {
                console.log('ğŸµ Starting recording playback at', currentTime);
                webAudio.setVolume(0.3);
                recorder.playRecordingsAtTime(currentTime);
            }
            setIsPlaying(true);
        }
    }, [webAudio, metronome, metronomeOn, recorder, currentTime]);

    const handleToggleJam = useCallback(async () => {
        console.log('ğŸ¤ handleToggleJam called', { isJamming, isInJamSection, currentTime, jamSectionRange });

        if (isJamming) {
            // STOP JAM: ë…¹ìŒ ì¢…ë£Œ - í˜„ì¬ ë§ˆë”” ë ì‹œê°„ìœ¼ë¡œ ë§ì¶¤
            const currentMeasureEndTime = currentMeasureStartTime + measureDuration;
            console.log('ğŸ¤ Stopping recording at measure end:', {
                currentTime,
                currentMeasureEndTime,
                globalMeasure
            });

            setIsJamming(false);
            await recorder.stopRecording(currentMeasureEndTime, globalMeasure);
            webAudio.pause();
            webAudio.setVolume(1); // ë³¼ë¥¨ ë³µêµ¬
            metronome.stop();
            setIsPlaying(false);

            showToast('success', 'ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤');
        } else {
            // START JAM: JAM ì„¹ì…˜ì¸ì§€ í™•ì¸
            if (!isInJamSection) {
                console.log('ğŸ¤ Not in JAM section, showing toast');
                showToast('warning', 'JAM ì„¹ì…˜ì—ì„œë§Œ ë…¹ìŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤');
                return;
            }

            // í˜„ì¬ ë§ˆë””ì— ê²¹ì¹˜ëŠ” ê¸°ì¡´ ë…¹ìŒì´ ìˆëŠ”ì§€ í™•ì¸
            const overlapping = recorder.getOverlappingSegment(globalMeasure, globalMeasure);
            if (overlapping) {
                const confirmed = window.confirm(
                    `ë§ˆë”” ${overlapping.startMeasure}-${overlapping.endMeasure}ì— ê¸°ì¡´ ë…¹ìŒì´ ìˆìŠµë‹ˆë‹¤. ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ?`
                );
                if (!confirmed) return;
                // ìƒˆ ë…¹ìŒì´ ê¸°ì¡´ ê²¹ì¹˜ëŠ” ë…¹ìŒì„ ìë™ìœ¼ë¡œ ëŒ€ì²´í•¨
            }

            // ê¶Œí•œ ìš”ì²­
            const hasPermission = await recorder.requestPermission();
            if (!hasPermission) return;

            // ë…¹ìŒ ì‹œì‘ - ë§ˆë”” ê²½ê³„ì— ë§ì¶¤ (currentMeasureStartTime ì‚¬ìš©)
            console.log('ğŸ¤ Starting recording at measure boundary:', {
                currentTime,
                currentMeasureStartTime,
                globalMeasure
            });
            const started = await recorder.startRecording(currentMeasureStartTime, globalMeasure);
            if (!started) return;

            setIsJamming(true);

            // ì˜¤ë””ì˜¤ë„ ë§ˆë”” ê²½ê³„ë¡œ seek í›„ ì¬ìƒ (ë³¼ë¥¨ ë‚®ì¶¤)
            webAudio.seek(currentMeasureStartTime);
            setCurrentTime(currentMeasureStartTime);
            webAudio.setVolume(0.3);
            await webAudio.play();
            if (metronomeOn) await metronome.start();
            setIsPlaying(true);
        }
    }, [isJamming, recorder, currentTime, currentMeasureStartTime, measureDuration, globalMeasure, jamSectionRange, isInJamSection, webAudio, metronome, metronomeOn, showToast]);

    const handleTimeChange = useCallback((newTime: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” seek ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        const clampedTime = Math.max(0, Math.min(newTime, duration));

        // ë…¹ìŒ ì¬ìƒ ì¤‘ì´ë©´ ì¼ì‹œì •ì§€ í›„ ìƒˆ ìœ„ì¹˜ì—ì„œ ì¬ì‹œì‘
        if (recorder.state === 'recorded') {
            recorder.pauseRecordings();

            // ë§Œì•½ ì¬ìƒ ì¤‘ì´ê³  ìƒˆ ìœ„ì¹˜ê°€ ë…¹ìŒ êµ¬ê°„ ë‚´ë¼ë©´, ë…¹ìŒë„ ìƒˆ ìœ„ì¹˜ì—ì„œ ì¬ìƒ
            if (webAudio.isPlaying && recorder.hasRecordingAt(clampedTime)) {
                webAudio.setVolume(0.3);
                // ì•½ê°„ì˜ ë”œë ˆì´ í›„ ì¬ìƒ ì‹œì‘ (seek ì™„ë£Œ ëŒ€ê¸°)
                setTimeout(() => {
                    recorder.playRecordingsAtTime(clampedTime);
                }, 50);
            } else if (!recorder.hasRecordingAt(clampedTime)) {
                // ë…¹ìŒ êµ¬ê°„ ë°–ìœ¼ë¡œ ì´ë™í•˜ë©´ ë³¼ë¥¨ ë³µêµ¬
                webAudio.setVolume(1.0);
            }
        }

        webAudio.seek(clampedTime);
        setCurrentTime(clampedTime);
    }, [duration, webAudio, isJamming, showToast, recorder]);

    const handleSeekByMeasures = useCallback((offset: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” seek ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        const newTime = webAudio.currentTime + (offset * measureDuration);
        handleTimeChange(newTime);
    }, [webAudio, measureDuration, handleTimeChange, isJamming, showToast]);

    // ë§ˆë”” í´ë¦­ ì‹œ í•´ë‹¹ ë§ˆë”” ì²˜ìŒìœ¼ë¡œ ì´ë™
    const handleMeasureClick = useCallback((globalMeasureIndex: number) => {
        // ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™ ì°¨ë‹¨
        if (isJamming) {
            showToast('warning', 'ë…¹ìŒ ì¤‘ì—ëŠ” ì´ë™í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
            return;
        }
        // globalMeasureIndexëŠ” 0-basedì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        const targetTime = globalMeasureIndex * measureDuration;
        handleTimeChange(targetTime);
    }, [measureDuration, handleTimeChange, isJamming, showToast]);

    const handleToggleJamOnly = useCallback((enabled: boolean) => {
        setJamOnlyMode(enabled);
        if (enabled && webAudio.currentTime < introEndTime) {
            handleTimeChange(introEndTime);
        }
    }, [webAudio, introEndTime, handleTimeChange]);

    const handleToggleMetronome = useCallback((enabled: boolean) => {
        setMetronomeOn(enabled);
        metronome.setMuted(!enabled);
        if(enabled && isPlaying) metronome.start();
        else metronome.stop();
    }, [metronome, isPlaying]);

    const handleSave = useCallback(async () => {
        if (!recorder.audioBlob || !recorder.recordingRange) {
            showToast('warning', 'ì €ì¥í•  ë…¹ìŒì´ ì—†ìŠµë‹ˆë‹¤');
            return;
        }

        // ë””ë²„ê¹…: ì €ì¥í•  ë°ì´í„° ì¶œë ¥
        console.log('ğŸµ [handleSave] recordingRange:', recorder.recordingRange);
        console.log('ğŸµ [handleSave] segments:', recorder.segments);

        setIsSaving(true);
        try {
            const saveParams = {
                songId: MOCK_SONG.id,
                audioBlob: recorder.audioBlob,
                startMeasure: recorder.recordingRange.startMeasure,
                endMeasure: recorder.recordingRange.endMeasure,
                startTime: recorder.recordingRange.startTime,
                endTime: recorder.recordingRange.endTime
            };
            console.log('ğŸµ [handleSave] uploadJamRecording params:', {
                ...saveParams,
                audioBlob: `Blob(${saveParams.audioBlob.size} bytes)`
            });

            const result = await uploadJamRecording(saveParams);

            if (result.success) {
                showToast('success', 'JAMì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!');
                recorder.resetRecording();
            } else {
                showToast('error', result.error || 'ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤');
            }
        } catch (error) {
            console.error('Save error:', error);
            showToast('error', 'ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤');
        } finally {
            setIsSaving(false);
        }
    }, [recorder, showToast]);

    // ë…¹ìŒ ì¼ì‹œì •ì§€/ì¬ê°œ í•¸ë“¤ëŸ¬
    const handlePauseResumeJamming = useCallback(() => {
        if (recorder.isPaused) {
            // ì¬ê°œ
            recorder.resumeJamming();
            webAudio.play();
            if (metronomeOn) metronome.start();
            setIsPlaying(true);
        } else {
            // ì¼ì‹œì •ì§€
            recorder.pauseJamming();
            webAudio.pause();
            metronome.stop();
            setIsPlaying(false);
        }
    }, [recorder, webAudio, metronome, metronomeOn]);

    useEffect(() => {
        const handleKeyDown = async (e: KeyboardEvent) => {
            if (e.target instanceof HTMLInputElement || e.target instanceof HTMLTextAreaElement) return;
            setPressedKey(e.code);
            switch (e.code) {
                case 'Space':
                    e.preventDefault();
                    // ë…¹ìŒ ì¤‘ì´ë©´ ì¼ì‹œì •ì§€/ì¬ê°œ
                    if (isJamming) {
                        handlePauseResumeJamming();
                    } else {
                        await handlePlayPause();
                    }
                    break;
                case 'KeyZ': e.preventDefault(); handleSeekByMeasures(-1); break;
                case 'KeyX': e.preventDefault(); handleSeekByMeasures(1); break;
                case 'KeyS': e.preventDefault(); handleToggleJamOnly(!jamOnlyMode); break;
                case 'KeyM': e.preventDefault(); handleToggleMetronome(!metronomeOn); break;
            }
        };
        const handleKeyUp = () => setPressedKey(null);
        window.addEventListener('keydown', handleKeyDown);
        window.addEventListener('keyup', handleKeyUp);
        return () => {
            window.removeEventListener('keydown', handleKeyDown);
            window.removeEventListener('keyup', handleKeyUp);
        };
    }, [handlePlayPause, handlePauseResumeJamming, handleSeekByMeasures, handleToggleJamOnly, handleToggleMetronome, jamOnlyMode, metronomeOn, isJamming]);

    useEffect(() => () => { webAudioRef.current.stop(); }, []);

    // í˜ì´ì§€ ì´íƒˆ ê²½ê³  (ë…¹ìŒ ì¤‘ ë˜ëŠ” ì €ì¥ë˜ì§€ ì•Šì€ ë…¹ìŒì´ ìˆì„ ë•Œ)
    useEffect(() => {
        const handleBeforeUnload = (e: BeforeUnloadEvent) => {
            if (isJamming || recorder.audioBlob) {
                e.preventDefault();
                e.returnValue = '';
            }
        };
        window.addEventListener('beforeunload', handleBeforeUnload);
        return () => window.removeEventListener('beforeunload', handleBeforeUnload);
    }, [isJamming, recorder.audioBlob]);

    // ë’¤ë¡œê°€ê¸° ë²„íŠ¼ í•¸ë“¤ëŸ¬ (í™•ì¸ í›„ ì´ë™)
    const handleBack = useCallback(() => {
        if (isJamming || recorder.audioBlob) {
            const confirmed = window.confirm(
                isJamming
                    ? 'ë…¹ìŒ ì¤‘ì…ë‹ˆë‹¤. ì •ë§ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?'
                    : 'ì €ì¥ë˜ì§€ ì•Šì€ ë…¹ìŒì´ ìˆìŠµë‹ˆë‹¤. ì •ë§ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?'
            );
            if (!confirmed) return;
        }
        router.back();
    }, [isJamming, recorder.audioBlob, router]);

    return (
        <div className="flex h-screen w-full flex-col overflow-hidden">
            <div className="mx-auto flex h-full w-full max-w-5xl flex-col overflow-hidden px-8 py-8">
                <div className="flex flex-col gap-2 flex-shrink-0">
                    <div className="flex justify-between items-center text-white">
                        <div className="flex items-center gap-4">
                            <button onClick={handleBack} className="p-2 hover:bg-white/10 rounded-full transition-colors"><ChevronLeft size={24} /></button>
                            <div>
                                <h1 className="text-2xl font-bold leading-none">{MOCK_SONG.title}</h1>
                                <span className="text-sm text-gray-400">{MOCK_SONG.artist}</span>
                            </div>
                        </div>
                        <div className="flex items-center gap-3">
                            {webAudio.isLoading && <div className="flex items-center gap-2 text-xs text-gray-400"><div className="w-3 h-3 border-2 border-gray-400 border-t-transparent rounded-full animate-spin" />ë¡œë”© ì¤‘...</div>}
                            <div className="px-3 py-1 border border-gray-600 rounded-full text-xs font-medium text-gray-300">SINGLE MODE</div>
                        </div>
                    </div>
                </div>

                <div className="flex-1 mt-4 relative min-h-0">
                    <div className="absolute -top-0 left-0 right-0 z-10 px-4 py-3 rounded-t-xl border border-b-0 border-gray-700 bg-[#0F172A]">
                        <div className="flex justify-between items-center text-white">
                            <div className="flex gap-6 text-sm font-mono text-gray-300">
                                <span>{formatTime(currentTime)} / {formatTime(duration)}</span>
                                <span>{currentSection?.label} - {globalMeasure}/{totalMeasures} ë§ˆë””</span>
                                {jamOnlyMode && <span className="text-[#7BA7FF]">JAM ONLY</span>}
                                {metronomeOn && <span className="text-[#FFD166]">â™ª {MOCK_SONG.bpm} BPM</span>}
                            </div>
                            {/* Recording/Processing Status */}
                            <div className="flex items-center gap-3">
                                {recorder.isProcessing && (
                                    <div className="text-sm flex items-center gap-2 text-yellow-400">
                                        <div className="w-3 h-3 border-2 border-yellow-400 border-t-transparent rounded-full animate-spin" />
                                        ì²˜ë¦¬ ì¤‘...
                                    </div>
                                )}
                                {isJamming && (
                                    <div className={`text-sm font-bold flex items-center gap-2 text-[#FF7B7B] ${recorder.isPaused ? '' : 'animate-pulse'}`}>
                                        <div className="w-2 h-2 rounded-full bg-[#FF7B7B]" />
                                        {recorder.isPaused ? 'PAUSED' : 'JAMMING'}
                                    </div>
                                )}
                                {recorder.state === 'recorded' && !isJamming && (
                                    <div className="text-sm flex items-center gap-2 text-green-400">
                                        <div className="w-2 h-2 rounded-full bg-green-400" />
                                        ë…¹ìŒ ì™„ë£Œ
                                    </div>
                                )}
                            </div>
                        </div>
                    </div>

                    <div className="h-full pt-12 rounded-xl border border-[#FFFFFF]/10 bg-[#FFFFFF]/5 overflow-hidden">
                        <SingleScore
                            sections={mockSections}
                            currentSectionIndex={currentSectionIndex}
                            currentMeasure={currentMeasureInSection}
                            measureProgress={measureProgress}
                            selectedMeasures={selectedMeasures}
                            onSelectionChange={handleSelectionChange}
                            onMeasureClick={handleMeasureClick}
                            recordedMeasures={recorder.recordedMeasures}
                        />
                    </div>
                </div>

                <div className="mt-6 flex-shrink-0 rounded-xl border border-[#FFFFFF]/10 bg-[#FFFFFF]/5 p-4 space-y-4">
                    <SinglePlayerBar
                        currentTime={currentTime}
                        duration={duration}
                        sections={playerBarSections}
                        onTimeChange={handleTimeChange}
                        recordedRanges={recordedRanges}
                    />
                    <SingleController
                        isPlaying={isPlaying}
                        onPlayPause={handlePlayPause}
                        onToggleJam={handleToggleJam}
                        isJamming={isJamming}
                        onSeekBackward={() => handleSeekByMeasures(-1)}
                        onSeekForward={() => handleSeekByMeasures(1)}
                        jamOnlyMode={jamOnlyMode}
                        onToggleJamOnly={handleToggleJamOnly}
                        metronomeOn={metronomeOn}
                        onToggleMetronome={handleToggleMetronome}
                        onSave={handleSave}
                        currentTime={currentTime}
                        duration={duration}
                        pressedKey={pressedKey}
                        isSaving={isSaving}
                        hasRecording={recorder.state === 'recorded'}
                    />
                </div>
            </div>
        </div>
    );
}